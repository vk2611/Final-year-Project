{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "### Inception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "21e59d94ce33661b4d0ee94a107474adfaddd909"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "#from generator import DataGenerator\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "import keras\n",
    "import os\n",
    "from keras.layers import Dropout\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir('../input/oct2017/OCT2017 /train/')\n",
    "train_datagen = ImageDataGenerator(samplewise_center=True, \n",
    "                              samplewise_std_normalization=True, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.05, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=15, \n",
    "                              zoom_range=0.15,\n",
    "                                   validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66788 images belonging to 4 classes.\n",
      "Found 16696 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "batch_size = 16\n",
    "train_data_dir = '../input/oct2017/OCT2017 /train'\n",
    "validation_data_dir = '../input/oct2017/OCT2017 /val'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMG_SIZE , IMG_SIZE),\n",
    "    batch_size=16,\n",
    "    subset='training',\n",
    "    class_mode='categorical')\n",
    "valid_X, valid_Y = next(train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMG_SIZE , IMG_SIZE),\n",
    "    batch_size=4000,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-5-83482eee2322>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-83482eee2322>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "t_x, t_y = next(train_generator)\n",
    "fig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\n",
    "for (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):2\n",
    "    c_ax.imshow(c_x[:,:,0], cmap = 'bone')\n",
    "    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(labels, c_y) \n",
    "                             if n_score>0.5]))\n",
    "    c_ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(64,(5,5),activation='relu',input_shape=(224,224,3),kernel_initializer='he_normal'))\n",
    "    #model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64,(5,5),activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(32,(5,5),activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(32,5,activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(16,(5,5),activation='relu',padding='same',kernel_initializer='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(128,activation='relu',kernel_initializer='he_normal'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(64,activation='relu',kernel_initializer='he_normal'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(32,activation='relu',kernel_initializer='he_normal'))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    #model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    #history=model.fit(x_train,y_train,epochs=12,batch_size=128,verbose=1,validation_data=(x_test,y_test))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_layer()\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
    "                           metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "100/100 [==============================] - 41s 407ms/step - loss: 1.2824 - acc: 0.4288 - val_loss: 1.2469 - val_acc: 0.4402\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44025, saving model to weights.best.hdf5\n",
      "Epoch 2/40\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 1.2267 - acc: 0.4619 - val_loss: 1.1976 - val_acc: 0.5012\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.44025 to 0.50125, saving model to weights.best.hdf5\n",
      "Epoch 3/40\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 1.0376 - acc: 0.6225 - val_loss: 0.8440 - val_acc: 0.6997\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.50125 to 0.69975, saving model to weights.best.hdf5\n",
      "Epoch 4/40\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.8713 - acc: 0.6806 - val_loss: 0.7568 - val_acc: 0.7165\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.69975 to 0.71650, saving model to weights.best.hdf5\n",
      "Epoch 5/40\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.8147 - acc: 0.7031 - val_loss: 0.7097 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71650 to 0.74250, saving model to weights.best.hdf5\n",
      "Epoch 6/40\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 0.7542 - acc: 0.7212 - val_loss: 0.7439 - val_acc: 0.7472\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.74250 to 0.74725, saving model to weights.best.hdf5\n",
      "Epoch 7/40\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.7495 - acc: 0.7300 - val_loss: 0.6596 - val_acc: 0.7558\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.74725 to 0.75575, saving model to weights.best.hdf5\n",
      "Epoch 8/40\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.6911 - acc: 0.7450 - val_loss: 0.6687 - val_acc: 0.7378\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75575\n",
      "Epoch 9/40\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.6957 - acc: 0.7550 - val_loss: 0.6460 - val_acc: 0.7592\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.75575 to 0.75925, saving model to weights.best.hdf5\n",
      "Epoch 10/40\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.6870 - acc: 0.7550 - val_loss: 0.6574 - val_acc: 0.7548\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.75925\n",
      "Epoch 11/40\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 0.6812 - acc: 0.7619 - val_loss: 0.6195 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.75925 to 0.76400, saving model to weights.best.hdf5\n",
      "Epoch 12/40\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.6991 - acc: 0.7338 - val_loss: 0.6165 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.76400 to 0.76525, saving model to weights.best.hdf5\n",
      "Epoch 13/40\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.6662 - acc: 0.7594 - val_loss: 0.6117 - val_acc: 0.7638\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.76525\n",
      "Epoch 14/40\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.6825 - acc: 0.7488 - val_loss: 0.6051 - val_acc: 0.7662\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.76525 to 0.76625, saving model to weights.best.hdf5\n",
      "Epoch 15/40\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.6762 - acc: 0.7556 - val_loss: 0.6039 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.76625\n",
      "Epoch 16/40\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.6440 - acc: 0.7631 - val_loss: 0.6250 - val_acc: 0.7668\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.76625 to 0.76675, saving model to weights.best.hdf5\n",
      "Epoch 17/40\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.7007 - acc: 0.7381 - val_loss: 0.6177 - val_acc: 0.7632\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.76675\n",
      "Epoch 18/40\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.6671 - acc: 0.7394 - val_loss: 0.6389 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.76675\n",
      "Epoch 19/40\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.6867 - acc: 0.7412 - val_loss: 0.6698 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.76675\n",
      "Epoch 20/40\n",
      "100/100 [==============================] - 32s 315ms/step - loss: 0.6675 - acc: 0.7662 - val_loss: 0.7593 - val_acc: 0.7258\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.76675\n",
      "Epoch 21/40\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.6348 - acc: 0.7738 - val_loss: 0.5948 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.76675 to 0.77650, saving model to weights.best.hdf5\n",
      "Epoch 22/40\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 0.6538 - acc: 0.7662 - val_loss: 0.5755 - val_acc: 0.7857\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.77650 to 0.78575, saving model to weights.best.hdf5\n",
      "Epoch 23/40\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.6393 - acc: 0.7569 - val_loss: 0.6072 - val_acc: 0.7815\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.78575\n",
      "Epoch 24/40\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 0.5964 - acc: 0.7775 - val_loss: 0.5838 - val_acc: 0.7808\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.78575\n",
      "Epoch 25/40\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.6405 - acc: 0.7562 - val_loss: 0.5995 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.78575\n",
      "Epoch 26/40\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.6018 - acc: 0.7769 - val_loss: 0.6267 - val_acc: 0.7865\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.78575 to 0.78650, saving model to weights.best.hdf5\n",
      "Epoch 27/40\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.5883 - acc: 0.7938 - val_loss: 0.5467 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.78650 to 0.80200, saving model to weights.best.hdf5\n",
      "Epoch 28/40\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.6187 - acc: 0.7756 - val_loss: 0.5736 - val_acc: 0.7930\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.80200\n",
      "Epoch 29/40\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.5983 - acc: 0.7781 - val_loss: 0.5591 - val_acc: 0.8045\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.80200 to 0.80450, saving model to weights.best.hdf5\n",
      "Epoch 30/40\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.5776 - acc: 0.7913 - val_loss: 0.5503 - val_acc: 0.8083\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.80450 to 0.80825, saving model to weights.best.hdf5\n",
      "Epoch 31/40\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.5722 - acc: 0.7956 - val_loss: 0.5557 - val_acc: 0.7965\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.80825\n",
      "Epoch 32/40\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.5772 - acc: 0.7906 - val_loss: 0.5278 - val_acc: 0.8037\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.80825\n",
      "Epoch 33/40\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.6097 - acc: 0.7825 - val_loss: 0.5348 - val_acc: 0.8087\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.80825 to 0.80875, saving model to weights.best.hdf5\n",
      "Epoch 34/40\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 0.5772 - acc: 0.7887 - val_loss: 0.5184 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.80875 to 0.81800, saving model to weights.best.hdf5\n",
      "Epoch 35/40\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.5621 - acc: 0.7975 - val_loss: 0.5194 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.81800\n",
      "Epoch 36/40\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 0.5491 - acc: 0.8006 - val_loss: 0.5676 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.81800\n",
      "Epoch 37/40\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.5446 - acc: 0.7938 - val_loss: 0.5208 - val_acc: 0.8193\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.81800 to 0.81925, saving model to weights.best.hdf5\n",
      "Epoch 38/40\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 0.5255 - acc: 0.8181 - val_loss: 0.4892 - val_acc: 0.8223\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.81925 to 0.82225, saving model to weights.best.hdf5\n",
      "Epoch 39/40\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.5348 - acc: 0.8094 - val_loss: 0.4857 - val_acc: 0.8325\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.82225 to 0.83250, saving model to weights.best.hdf5\n",
      "Epoch 40/40\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.4897 - acc: 0.8244 - val_loss: 0.4856 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.83250\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit_generator(train_generator, \n",
    "                                  steps_per_epoch=100,\n",
    "                                  validation_data = (valid_X,valid_Y), \n",
    "                                  epochs = 40,\n",
    "                                  callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_layer()\n",
    "model.load_weights(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16696 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# creating test data\n",
    "test_X, test_Y = next(train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMG_SIZE , IMG_SIZE),\n",
    "    batch_size=8000,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = []\n",
    "for i in range(len(y_pred)):\n",
    "    pred_class.append(np.argmax(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_class = []\n",
    "for i in range(len(test_Y)):\n",
    "    actual_class.append(np.argmax(test_Y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.831125\n"
     ]
    }
   ],
   "source": [
    "#  accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy = ',accuracy_score(pred_class,actual_class))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
